{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d6aee4-9deb-4de9-9e2c-cc51fb4de67a",
   "metadata": {},
   "source": [
    "# Testing llama3 ela question generation against the regents test questions using semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5a295-8cfa-4363-aab8-706c0f94508a",
   "metadata": {},
   "source": [
    "The task of creating questions based off of a passage seems much less daunting for an LLM than generating a passage or texts from just a topic. Our hypothesis is that the llms perform much better in the question generation tasks. Especially when the model gets a few shots of the quality of questions that are going to be used to grade them.\n",
    "\n",
    "Approach: \n",
    "1. Provide the 8b llama3 model with a passage from the Regents exam in the same grade level + the Regents questions\n",
    "2. Ask the model to produce questions of a test passage that we will be using. The amount of questions should be the same amount as the amount in regents test questions.\n",
    "3. Test semantic similiraty using two scores\n",
    "\n",
    "# Data\n",
    "\n",
    "The Regents information is publicy available in pdf format\n",
    "The other data is generated by the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d7f6c4-a5ca-45c9-8b47-242100b4bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Ensures that plots appear in the notebook itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f6afb-fa69-4a30-9aa7-c577ab70a9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ea18e-61a6-49f0-8265-7ff35d18491e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9fdd8-df8e-4e4c-a5f1-994c509b5d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
